{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn import CTCLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import TextDataset as TDataset\n",
    "from data.data_utils import collate_fn\n",
    "from trainer.train import train\n",
    "from trainer.sequence_decoder import ctc_decode\n",
    "from modeling.model_utils import load_model\n",
    "\n",
    "from configs.config_crnn import train_config\n",
    "from configs.dataconfig import (\n",
    "    train_source, val_source, mapper, test_sources\n",
    ")\n",
    "from utils.augment import Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_crnn_model(cfg, num_class, reload_checkpoint = ''):\n",
    "    from modeling.crnn import Crnn\n",
    "    config = cfg\n",
    "\n",
    "    crnn = Crnn(\n",
    "        1, \n",
    "        num_class,\n",
    "        map_to_seq_hidden=config['map_to_seq_hidden'],\n",
    "        rnn_hidden=config['rnn_hidden'],\n",
    "        leaky_relu=config['leaky_relu']\n",
    "    )\n",
    "\n",
    "    if reload_checkpoint:\n",
    "        crnn = load_model(crnn, reload_checkpoint)\n",
    "        print('model loaded successfully')\n",
    "\n",
    "    return crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Tokenizer: TrieTokenizer\n",
      "Max Sequence Length: 64\n",
      "Normalize Text: True\n",
      "Normalizar: unicode\n",
      "Normalization Mode: NFKC\n",
      "Warning: \"out_of_vocabulary_info\" will be updated as per new vocab\n",
      "update completed.[2143] new vocabs added. Current vocab count: 2145\n"
     ]
    }
   ],
   "source": [
    "from BnTokenizer import TrieTokenizer\n",
    "from BnTokenizer.base import BnGraphemizer\n",
    "\n",
    "tokenizer = BnGraphemizer(\n",
    "    tokenizer_class=TrieTokenizer,\n",
    "    max_len=64,\n",
    "    normalize_unicode=True,\n",
    "    normalization_mode='NFKC',\n",
    "    normalizer=\"unicode\",\n",
    "    printer=print\n",
    ")\n",
    "\n",
    "graphemes = json.load(open(\"graphemes.json\", 'r'))\n",
    "tokenizer.add_tokens(graphemes,reset_oov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crnn(\n",
       "  (features_extractor): FeatureExtractor(\n",
       "    (feature_extractor): ModuleList(\n",
       "      (0): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (map_to_seq): Linear(in_features=512, out_features=96, bias=True)\n",
       "  (rnn1): LSTM(96, 256, bidirectional=True)\n",
       "  (rnn2): LSTM(512, 256, bidirectional=True)\n",
       "  (dense): Linear(in_features=512, out_features=2146, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "model = define_crnn_model(train_config, len(tokenizer.vocab) + 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crnn(\n",
       "  (features_extractor): FeatureExtractor(\n",
       "    (feature_extractor): ModuleList(\n",
       "      (0): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Convolution(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (map_to_seq): Linear(in_features=512, out_features=96, bias=True)\n",
       "  (rnn1): LSTM(96, 256, bidirectional=True)\n",
       "  (rnn2): LSTM(512, 256, bidirectional=True)\n",
       "  (dense): Linear(in_features=512, out_features=2146, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint =  torch.load(\n",
    "    \"/mnt/JaHiD/Zahid/RnD/TokenizerForBengaliTextRecognition/artifacts/crnn/CRNN+GRAPHEMIZER+BTHR+Boise/crnn_044500_loss_0.8612_acc_0.8996.pt\"\n",
    ")\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.utils import levenshtein_distance\n",
    "from trainer.evaluate import predict\n",
    "\n",
    "\n",
    "def inference(\n",
    "    cfg, model, inf_loader,tokenizer,\n",
    "    decode_method='beam_search',\n",
    "    beam_size=10,\n",
    "    save_image=True,\n",
    "    save_excel_report=True\n",
    "):\n",
    "    \n",
    "    fun = lambda x: ''.join([tokenizer.vocab[i] for i in x]).replace('<oov>', '‚ñÅ')\n",
    "    prediciton_info = predict(\n",
    "        model, inf_loader,tokenizer,\n",
    "        decode_method=decode_method,\n",
    "        beam_size=beam_size\n",
    "    )\n",
    "    (all_gts, all_preds, _, who_are_we) = prediciton_info\n",
    "\n",
    "    report = pd.DataFrame.from_dict((\n",
    "        {\n",
    "            'GroundTruth':list(map(fun,all_gts)),\n",
    "            'Prediction': list(map(fun,all_preds))\n",
    "        }\n",
    "    ))\n",
    "\n",
    "    report['Edit Distance'] = list(\n",
    "        map(lambda x: levenshtein_distance(*x,True),\n",
    "        zip(report['GroundTruth'], report['Prediction']))\n",
    "    )\n",
    "    report['GT Length'] = [len(i) for i in report['GroundTruth']]\n",
    "    report['Split'] = [i.split('|')[0] for i in who_are_we]\n",
    "    report['Path'] =  [i.split('|')[-1] for i in who_are_we]\n",
    "\n",
    "    if save_excel_report:\n",
    "        saving_dir = f\"{cfg['checkpoints_dir']}/report.checkpoints.{who_are_we[0].split('|')[0]}.test.xlsx\"\n",
    "        report.to_excel(\n",
    "            f\"{cfg['checkpoints_dir']}/report.checkpoints.{who_are_we[0].split('|')[0]}.test.textonly.xlsx\"\n",
    "        )\n",
    "\n",
    "    if save_image:\n",
    "        writer = pd.ExcelWriter(saving_dir, engine='xlsxwriter')\n",
    "        report.to_excel(writer, sheet_name='Sheet1')\n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "        i = 2\n",
    "        for img in report['Path']:\n",
    "            worksheet.insert_image(f'H{i}', img)\n",
    "            i += 1\n",
    "        writer.save()\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sources = {\n",
    "    \"boise_camera_test\": {\n",
    "        'data': '/home/jahid/Music/bn_dataset/boiseState/camera/split/test_annotaion.json',\n",
    "        'base_dir': '/home/jahid/Music/bn_dataset/boiseState/camera/split/test_crop_images',\n",
    "        'id': 'boise_camera_test'\n",
    "    },\n",
    "    \"boise_scan_test\": {\n",
    "        'data': '/home/jahid/Music/bn_dataset/boiseState/scan/split/test_annotaion.json',\n",
    "        'base_dir': '/home/jahid/Music/bn_dataset/boiseState/scan/split/test_crop_images',\n",
    "        'id': 'boise_scan_test'\n",
    "    },\n",
    "    \"boise_conjunct_test\": {\n",
    "        'data': '/home/jahid/Music/bn_dataset/boiseState/conjunct/split/test_annotaion.json',\n",
    "        'base_dir': '/home/jahid/Music/bn_dataset/boiseState/conjunct/split/test_crop_images',\n",
    "        'id': 'boise_conjunct_test'\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boise_conjunct_test None\n",
      "Out of 725 boise_conjunct_test,725 are kept after filtering\n",
      "Total data 725\n",
      "Total 725 Images found!!!\n",
      "0/6 is in progress\n",
      "1/6 is in progress\n",
      "2/6 is in progress\n",
      "3/6 is in progress\n",
      "4/6 is in progress\n",
      "5/6 is in progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49959/3025612220.py:53: FutureWarning: save is not part of the public API, usage can give in unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "from data.data_source_controller import DataSourceController\n",
    "for k, v in test_sources.items():\n",
    "    if k not in  [\n",
    "        # 'bn_htr_test',\n",
    "        # 'boise_scan_test',\n",
    "        # 'boise_camera_test',\n",
    "        'boise_conjunct_test'\n",
    "    ]: \n",
    "        continue\n",
    "    process_text = lambda x : x.replace('\\u200c','').replace(\"\\u200d\", '')\n",
    "    val_data = DataSourceController(filter=lambda x: len(x.label)<30, transform= process_text)\n",
    "\n",
    "    print(k,v.get('n'))\n",
    "    val_data.add_data(**v)\n",
    "\n",
    "    val_dataset = TDataset(\n",
    "        val_data.data,\n",
    "        tokenizer,\n",
    "        img_height= 32,\n",
    "        img_width= 128\n",
    "    )\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size= train_config['train_batch_size'], \n",
    "        collate_fn=collate_fn, \n",
    "        prefetch_factor = 1,\n",
    "        num_workers = 4\n",
    "    )\n",
    "    report = inference(\n",
    "        train_config, model, val_dataloader,tokenizer,\n",
    "        save_image=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49959/1437947574.py:17: FutureWarning: save is not part of the public API, usage can give in unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "# Save Misprediciton Log\n",
    "import glob\n",
    "\n",
    "for xl in sorted(glob.glob(f\"{train_config['checkpoints_dir']}/*only.xlsx\")):\n",
    "    _report = pd.read_excel(xl, engine='openpyxl').fillna('')\n",
    "    _report = _report[_report['Edit Distance']>0]\n",
    "\n",
    "    writer = pd.ExcelWriter(xl.replace('.xlsx', '.error.xlsx'), engine='xlsxwriter')\n",
    "    _report.to_excel(writer, sheet_name='Sheet1')\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "    i = 2\n",
    "    for img in _report['Path']:\n",
    "        worksheet.insert_image(f'K{i}', img)\n",
    "        i += 1\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report.checkpoints.boise_conjunct_test.test.textonly.xlsx\n",
      "    Char Error Rate tensor(0.0637)\n",
      "    Word Error Rate 0.18068965517241378\n",
      "    Word Accuracy 0.8193103448275862\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "process_text = lambda x : x.replace('\\u200c','')\n",
    "for xl in sorted(glob.glob(f\"{train_config['checkpoints_dir']}/*only.xlsx\")):\n",
    "    _report = pd.read_excel(xl).fillna('')\n",
    "    try:\n",
    "        _report['GroundTruth'] = _report['GroundTruth'].apply(process_text)\n",
    "        _report['Prediction'] = _report['Prediction'].apply(process_text)\n",
    "        print(xl.split('/')[-1])\n",
    "        print(\"    Char Error Rate\",torchmetrics.CharErrorRate()(_report['GroundTruth'], _report['Prediction']))\n",
    "        print(\"    Word Error Rate\",sum(_report['GroundTruth'] !=_report['Prediction'])/len(_report))\n",
    "        print(\"    Word Accuracy\",sum(_report['GroundTruth'] ==_report['Prediction'])/len(_report))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(xl.split('/')[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch1.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed5d878878b9f6b71826320145ffe862892db6a15203f4cdc0137670dfd93d2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
